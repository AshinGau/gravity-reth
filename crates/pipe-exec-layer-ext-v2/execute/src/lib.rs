//! Pipeline execution layer extension
#[macro_use]
mod channel;
mod metrics;
pub mod onchain_config;

use channel::Channel;
use gravity_api_types::{
    config_storage::{ConfigStorage, OnChainConfig, OnChainConfigResType},
    events::contract_event::GravityEvent,
};
use metrics::PipeExecLayerMetrics;

use alloy_consensus::{
    constants::EMPTY_WITHDRAWALS, BlockHeader, Header, Transaction, EMPTY_OMMER_ROOT_HASH,
};
use alloy_eips::{eip4895::Withdrawals, merge::BEACON_NONCE};
use alloy_primitives::{
    map::{HashMap, HashSet},
    Address, TxHash, B256, U256,
};
use alloy_rpc_types_eth::TransactionRequest;
use rayon::iter::{IntoParallelIterator, ParallelIterator};
use reth_chain_state::{ExecutedBlockWithTrieUpdates, ExecutedTrieUpdates};
use reth_chainspec::{ChainSpec, EthereumHardforks};
use reth_ethereum_primitives::{Block, BlockBody, Receipt, TransactionSigned};
use reth_evm::{ConfigureEvm, NextBlockEnvAttributes, ParallelDatabase};
use reth_evm_ethereum::EthEvmConfig;
use reth_execution_types::{BlockExecutionOutput, ExecutionOutcome};
use reth_pipe_exec_layer_event_bus::{
    MakeCanonicalEvent, PipeExecLayerEvent, PipeExecLayerEventBus, WaitForPersistenceEvent,
    PIPE_EXEC_LAYER_EVENT_BUS,
};
use reth_primitives::EthPrimitives;
use reth_primitives_traits::{
    proofs::{self},
    Block as _, RecoveredBlock,
};
use reth_provider::{OriginalValuesKnown, PersistBlockCache, PERSIST_BLOCK_CACHE};
use reth_rpc_eth_api::RpcTypes;
use revm::{
    database::{states::bundle_state::BundleRetention, State},
    state::AccountInfo,
    DatabaseCommit,
};
use std::{collections::BTreeMap, sync::Arc, time::Instant};

use gravity_storage::GravityStorage;
use onchain_config::{transact_metadata_contract_call, OnchainConfigFetcher};
use reth_rpc_eth_api::helpers::EthCall;
use reth_trie::{HashedPostState, KeccakKeyHasher};
use tokio::sync::{
    mpsc::{UnboundedReceiver, UnboundedSender},
    oneshot, Mutex,
};
use tracing::*;

/// Metadata about an executed block
#[derive(Debug, Clone, Copy)]
pub struct ExecutedBlockMeta {
    /// Which ordered block is used to execute the block
    pub block_id: B256,
    /// Block hash of the executed block
    pub block_hash: B256,
    /// Block number of the executed block
    pub block_number: u64,
}

/// An ordered block received from Coordinator for execution
#[derive(Debug)]
pub struct OrderedBlock {
    /// Epoch of the block
    pub epoch: u64,
    /// `BlockId` of the parent block generated by Gravity SDK
    pub parent_id: B256,
    /// `BlockId` of the block generated by Gravity SDK
    pub id: B256,
    /// Block number of the block
    pub number: u64,
    /// Timestamp of the block
    pub timestamp: u64,
    /// Coinbase address of the block
    pub coinbase: Address,
    /// Block header mix hash, used as prevRandao in the block
    pub prev_randao: B256,
    /// Withdrawals in the block, if any
    /// See <https://github.com/ethereum/execution-apis/blob/6709c2a795b707202e93c4f2867fa0bf2640a84f/src/engine/shanghai.md#executionpayloadv2>
    pub withdrawals: Withdrawals,
    /// Ordered transactions in the block
    pub transactions: Vec<TransactionSigned>,
    /// Senders of the transactions in the block
    pub senders: Vec<Address>,
}

enum ReceivedBlock {
    /// Block received from Coordinator
    #[allow(clippy::large_enum_variant)]
    OrderedBlock(OrderedBlock),
    /// History block to be processed. Only used for testing.
    HistoryBlock(Box<RecoveredBlock<Block>>),
}

impl ReceivedBlock {
    fn id(&self) -> B256 {
        match self {
            Self::OrderedBlock(block) => block.id,
            Self::HistoryBlock(block) => block.hash(),
        }
    }

    fn parent_id(&self) -> B256 {
        match self {
            Self::OrderedBlock(block) => block.parent_id,
            Self::HistoryBlock(block) => block.parent_hash(),
        }
    }

    fn number(&self) -> u64 {
        match self {
            Self::OrderedBlock(block) => block.number,
            Self::HistoryBlock(block) => block.number(),
        }
    }
}

/// Events emitted by the pipeline execution layer
#[derive(Debug)]
pub struct ExecutionArgs {
    /// The latest block number and its corresponding block id.
    pub block_number_to_block_id: BTreeMap<u64, B256>,
}

/// Owned by EL
#[derive(Debug)]
struct PipeExecService<Storage: GravityStorage> {
    /// Immutable part of the state
    core: Arc<Core<Storage>>,
    /// Receive ordered block from Coordinator
    ordered_block_rx: UnboundedReceiver<ReceivedBlock>,
    /// Receive the execution init args from `GravitySDK`
    execution_args_rx: oneshot::Receiver<ExecutionArgs>,
}

/// Information about a transaction in the executed block
#[derive(Debug, Clone)]
pub struct TxInfo {
    /// Transaction hash
    pub tx_hash: TxHash,
    /// Sender address of the transaction
    pub sender: Address,
    /// Nonce of the transaction
    pub nonce: u64,
    /// Whether the transaction is discarded due to validation failure
    pub is_discarded: bool,
}

/// Result of the executed block
#[derive(Debug, Clone)]
pub struct ExecutionResult {
    /// Block id of the executed block
    /// This is the block id generated by Gravity SDK
    pub block_id: B256,
    /// Block number of the executed block
    pub block_number: u64,
    /// Block hash of the executed block
    /// This is the block hash generated by EL after execution and merklization
    pub block_hash: B256,
    /// Information about the transactions in the executed block
    pub txs_info: Vec<TxInfo>,
    /// Gravity events emitted by the executed block
    pub gravity_events: Vec<GravityEvent>,
}

#[derive(Debug, Clone)]
struct ExecuteBlockContext {
    parent_header: Header,
    prev_start_execute_time: Instant,
    epoch: u64,
}

#[derive(Debug)]
struct Core<Storage: GravityStorage> {
    /// Send executed block hash to Coordinator
    execution_result_tx: UnboundedSender<ExecutionResult>,
    /// Receive verified block hash from Coordinator
    verified_block_hash_rx: Arc<Channel<B256 /* block id */, Option<B256> /* block hash */>>,
    storage: Arc<Storage>,
    evm_config: EthEvmConfig,
    chain_spec: Arc<ChainSpec>,
    event_tx: std::sync::mpsc::Sender<PipeExecLayerEvent<EthPrimitives>>,
    execute_block_barrier: Channel<u64 /* block number */, ExecuteBlockContext>,
    merklize_barrier: Channel<u64 /* block number */, ()>,
    seal_barrier: Channel<u64 /* block number */, B256 /* block hash */>,
    make_canonical_barrier: Channel<u64 /* block number */, Instant>,
    discard_txs_tx: UnboundedSender<Vec<TxHash>>,
    cache: PersistBlockCache,
    metrics: PipeExecLayerMetrics,
}

impl<Storage: GravityStorage> PipeExecService<Storage> {
    async fn run(mut self) {
        self.core.init_storage(self.execution_args_rx.await.unwrap());
        loop {
            let start_time = Instant::now();
            let block = match self.ordered_block_rx.recv().await {
                Some(block) => block,
                None => {
                    self.core.execute_block_barrier.close();
                    self.core.merklize_barrier.close();
                    self.core.make_canonical_barrier.close();
                    return;
                }
            };
            let elapsed = start_time.elapsed();
            self.core.metrics.recv_block_time_diff.record(elapsed);
            info!(target: "PipeExecService.run",
                id=?block.id(),
                parent_id=?block.parent_id(),
                number=?block.number(),
                elapsed=?elapsed,
                "new ordered block"
            );

            let core = self.core.clone();
            tokio::spawn(async move {
                let start_time = Instant::now();
                core.process(block).await;
                core.metrics.process_block_duration.record(start_time.elapsed());
            });
        }
    }
}

const BLOCK_GAS_LIMIT_1G: u64 = 1_000_000_000;

#[derive(Debug)]
struct ExecuteOrderedBlockResult {
    /// Block without roots and block hash
    block: Block,
    senders: Vec<Address>,
    execution_output: BlockExecutionOutput<Receipt>,
    txs_info: Vec<TxInfo>,
    gravity_events: Vec<GravityEvent>,
    epoch: u64,
}

impl<Storage: GravityStorage> Core<Storage> {
    async fn process(&self, block: ReceivedBlock) {
        // Wait untile there's no large gap between cache and db
        let block_number = block.number();
        let block_id = block.id();
        self.metrics.start_process_block_number.set(block_number as f64);

        // Retrieve the parent block header to generate the necessary configs for
        // executing the current block
        let ExecuteBlockContext { parent_header, prev_start_execute_time, epoch } =
            self.execute_block_barrier.wait(block_number - 1).await.unwrap();

        if let ReceivedBlock::OrderedBlock(ordered_block) = &block {
            if ordered_block.epoch != epoch {
                // Discard the block if the epoch is not equal to the current epoch
                self.execute_block_barrier.notify(
                    block_number - 1,
                    ExecuteBlockContext { parent_header, prev_start_execute_time, epoch },
                );
                info!(target: "PipeExecService.process",
                    block_number=?block_number,
                    block_id=?block_id,
                    block_epoch=?ordered_block.epoch,
                    current_epoch=?epoch,
                    "epoch mismatch"
                );
                assert!(ordered_block.epoch < epoch);
                return;
            }
        }

        self.storage.insert_block_id(block_number, block_id);

        self.cache.wait_persist_gap();
        let start_time = Instant::now();
        let ExecuteOrderedBlockResult {
            mut block,
            senders,
            execution_output,
            txs_info,
            gravity_events,
            epoch,
        } = match block {
            ReceivedBlock::OrderedBlock(ordered_block) => {
                self.execute_ordered_block(ordered_block, &parent_header)
            }
            ReceivedBlock::HistoryBlock(recovered_block) => {
                self.execute_history_block(*recovered_block)
            }
        };
        let write_start = Instant::now();
        self.cache.write_state_changes(
            block_number,
            OriginalValuesKnown::No,
            &execution_output.state.state,
            &execution_output.state.contracts,
        );
        let hashed_state =
            HashedPostState::from_bundle_state::<KeccakKeyHasher>(&execution_output.state.state);
        self.metrics.cache_account_state.record(write_start.elapsed());
        let elapsed = start_time.elapsed();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            gas_used=execution_output.gas_used,
            elapsed=?elapsed,
            epoch=?epoch,
            "block executed"
        );
        self.metrics.execute_duration.record(elapsed);
        self.metrics.start_execute_time_diff.record(start_time - prev_start_execute_time);
        debug_assert_eq!(
            execution_output.gas_used, block.gas_used,
            "gas_used mismatch, block_number: {}",
            block.number,
        );
        self.execute_block_barrier
            .notify(
                block_number,
                ExecuteBlockContext {
                    parent_header: block.header.clone(),
                    prev_start_execute_time: start_time,
                    epoch,
                },
            )
            .unwrap();

        let execution_outcome = self.calculate_roots(&mut block, execution_output);

        // Merkling the state trie
        self.merklize_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        let (state_root, trie_updates) = self.storage.state_root(&hashed_state).unwrap();
        let write_start = Instant::now();
        self.cache.write_trie_updates(&trie_updates, block_number);
        self.metrics.cache_trie_state.record(write_start.elapsed());
        let elapsed = start_time.elapsed();
        self.metrics.merklize_duration.record(elapsed);
        self.merklize_barrier.notify(block_number, ()).unwrap();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            state_root=?state_root,
            elapsed=?elapsed,
            "state trie merklized"
        );
        block.header.state_root = state_root;

        // Seal the block
        let parent_hash = self.seal_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        block.header.parent_hash = parent_hash;
        let sealed_block = block.seal_slow();
        let block_hash = sealed_block.hash();
        self.metrics.seal_duration.record(start_time.elapsed());
        self.seal_barrier.notify(block_number, block_hash).unwrap();
        debug!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?block_hash,
            header=?sealed_block.header(),
            "block sealed"
        );

        let gas_used = sealed_block.gas_used;
        let executed_block = ExecutedBlockWithTrieUpdates::new(
            Arc::new(RecoveredBlock::new_sealed(sealed_block, senders)),
            Arc::new(execution_outcome),
            Arc::new(hashed_state),
            ExecutedTrieUpdates::empty(),
            Arc::new(trie_updates),
        );
        let execution_result =
            ExecutionResult { block_id, block_number, block_hash, txs_info, gravity_events };

        self.verify_executed_block_hash(execution_result).await.unwrap();
        self.make_canonical(&block_id, executed_block).await;
        self.metrics.total_gas_used.increment(gas_used);
        self.metrics.end_process_block_number.set(block_number as f64);
    }

    /// Push executed block hash to Coordinator and wait for verification result from Coordinator.
    /// Returns `None` if the channel has been closed.
    async fn verify_executed_block_hash(&self, execution_result: ExecutionResult) -> Option<()> {
        let start_time = Instant::now();
        let block_id = execution_result.block_id;
        let block_number = execution_result.block_number;
        let executed_block_hash = execution_result.block_hash;
        self.execution_result_tx.send(execution_result).ok()?;
        let block_hash = self.verified_block_hash_rx.wait(block_id).await?;
        if let Some(block_hash) = block_hash {
            assert_eq!(executed_block_hash, block_hash);
        }
        let elapsed = start_time.elapsed();
        self.metrics.verify_duration.record(elapsed);
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?executed_block_hash,
            elapsed=?elapsed,
            "block verified"
        );
        Some(())
    }

    fn create_block_for_executor(
        &self,
        ordered_block: OrderedBlock,
        base_fee: u64,
        state: &Storage::StateView,
    ) -> (RecoveredBlock<Block>, Vec<TxInfo>) {
        assert_eq!(ordered_block.transactions.len(), ordered_block.senders.len());
        let mut block = Block {
            header: Header {
                beneficiary: ordered_block.coinbase,
                timestamp: ordered_block.timestamp,
                mix_hash: ordered_block.prev_randao,
                base_fee_per_gas: Some(base_fee),
                number: ordered_block.number,
                gas_limit: BLOCK_GAS_LIMIT_1G,
                ommers_hash: EMPTY_OMMER_ROOT_HASH,
                nonce: BEACON_NONCE.into(),
                ..Default::default()
            },
            body: BlockBody::default(),
        };

        if self.chain_spec.is_shanghai_active_at_timestamp(block.timestamp) {
            if ordered_block.withdrawals.is_empty() {
                block.header.withdrawals_root = Some(EMPTY_WITHDRAWALS);
                block.body.withdrawals = Some(Withdrawals::default());
            } else {
                block.header.withdrawals_root =
                    Some(proofs::calculate_withdrawals_root(&ordered_block.withdrawals));
                block.body.withdrawals = Some(ordered_block.withdrawals);
            }
        }

        // only determine cancun fields when active
        if self.chain_spec.is_cancun_active_at_timestamp(block.timestamp) {
            // FIXME: Is it OK to use the parent's block id as `parent_beacon_block_root` before
            // execution?
            block.header.parent_beacon_block_root = Some(ordered_block.parent_id);

            // TODO(nekomoto): fill `excess_blob_gas` and `blob_gas_used` fields
            block.header.excess_blob_gas = Some(0);
            block.header.blob_gas_used = Some(0);
        }

        // Discard the invalid txs
        let start_time = Instant::now();
        let (txs, senders, txs_info) = self.filter_invalid_txs(
            state,
            ordered_block.transactions,
            ordered_block.senders,
            base_fee,
            block.gas_limit,
        );
        self.metrics.filter_transaction_duration.record(start_time.elapsed());

        block.body.transactions = txs;
        (RecoveredBlock::new_unhashed(block, senders), txs_info)
    }

    fn execute_ordered_block(
        &self,
        ordered_block: OrderedBlock,
        parent_header: &Header,
    ) -> ExecuteOrderedBlockResult {
        let block_id = ordered_block.id;
        let parent_id = ordered_block.parent_id;
        let block_number = ordered_block.number;
        assert_eq!(block_number, parent_header.number + 1);
        let epoch = ordered_block.epoch;

        let state = self.storage.get_state_view().unwrap();

        let mut evm_env = self
            .evm_config
            .next_evm_env(
                parent_header,
                &NextBlockEnvAttributes {
                    timestamp: ordered_block.timestamp,
                    suggested_fee_recipient: ordered_block.coinbase,
                    prev_randao: ordered_block.prev_randao,
                    gas_limit: BLOCK_GAS_LIMIT_1G,
                    parent_beacon_block_root: Some(ordered_block.parent_id),
                    withdrawals: Some(ordered_block.withdrawals.clone()),
                },
            )
            .unwrap();
        debug!(target: "execute_ordered_block",
            evm_env=?evm_env,
            block_number=?block_number,
        );
        let base_fee = evm_env.block_env.basefee;

        let (metadata_txn_result, state_changes) = {
            let mut state = State::builder().with_database_ref(&state).with_bundle_update().build();
            // Since we create one legacy txn, we should skip the base fee check
            // FIXME: This is a hack, we should find a more elegant way to do this
            evm_env.cfg_env.disable_base_fee = true;
            let mut evm = self.evm_config.evm_with_env(&mut state, evm_env);
            let (metadata_txn_result, state_changes) =
                transact_metadata_contract_call(&mut evm, ordered_block.timestamp * 1_000_000);
            drop(evm);

            if let Some((new_epoch, validators)) = metadata_txn_result.emit_new_epoch() {
                // New epoch triggered, advance epoch and discard the block.
                assert_eq!(new_epoch, epoch + 1);
                info!(target: "execute_ordered_block",
                    id=?block_id,
                    parent_id=?parent_id,
                    number=?block_number,
                    new_epoch=?new_epoch,
                    "emit new epoch, discard the block"
                );
                state.commit(state_changes);
                state.merge_transitions(BundleRetention::Reverts);
                return metadata_txn_result.into_executed_ordered_block_result(
                    &ordered_block,
                    state.take_bundle(),
                    validators,
                );
            }

            (metadata_txn_result, state_changes)
        };

        let (block, txs_info) = self.create_block_for_executor(ordered_block, base_fee, &state);

        info!(target: "execute_ordered_block",
            id=?block_id,
            parent_id=?parent_id,
            number=?block_number,
            num_txs=?block.transaction_count(),
            "ready to execute block"
        );

        let mut executor = self.evm_config.parallel_executor(state);
        // Apply metadata transaction result to executor state
        executor.commit_changes(state_changes);
        let outcome = executor.execute(&block).unwrap_or_else(|err| {
            serde_json::to_writer(
                std::io::BufWriter::new(std::fs::File::create(format!("{block_id}.json")).unwrap()),
                &block,
            )
            .unwrap();
            panic!("failed to execute block {block_id:?}: {err:?}")
        });

        let (mut block, senders) = block.split();
        block.header.gas_used = outcome.gas_used;
        let mut result = ExecuteOrderedBlockResult {
            block,
            senders,
            execution_output: outcome,
            txs_info,
            gravity_events: vec![],
            epoch,
        };
        metadata_txn_result.insert_to_executed_ordered_block_result(&mut result);
        result
    }

    /// Only used for testing.
    fn execute_history_block(&self, block: RecoveredBlock<Block>) -> ExecuteOrderedBlockResult {
        let state = self.storage.get_state_view().unwrap();
        let mut executor = self.evm_config.parallel_executor(state);
        let outcome = executor.execute(&block).unwrap_or_else(|err| {
            serde_json::to_writer(
                std::io::BufWriter::new(
                    std::fs::File::create(format!("{}.json", block.number)).unwrap(),
                ),
                &block,
            )
            .unwrap();
            panic!("failed to execute block {:?}: {:?}", block.number, err)
        });
        let (block, senders) = block.split();
        ExecuteOrderedBlockResult {
            block,
            senders,
            execution_output: outcome,
            txs_info: vec![],
            gravity_events: vec![],
            epoch: 0,
        }
    }

    /// Calculate the receipts root, logs bloom, and transactions root, etc. and fill them into the
    /// block header.
    fn calculate_roots(
        &self,
        block: &mut Block,
        execution_output: BlockExecutionOutput<Receipt>,
    ) -> ExecutionOutcome {
        // only determine cancun fields when active
        if self.chain_spec.is_prague_active_at_timestamp(block.timestamp) {
            block.header.requests_hash = Some(execution_output.requests.requests_hash());
        }

        let execution_outcome = ExecutionOutcome::new(
            execution_output.state,
            vec![execution_output.result.receipts],
            block.number,
            vec![execution_output.result.requests],
        );

        // Fill the block header with the calculated values
        block.header.transactions_root =
            proofs::calculate_transaction_root(&block.body.transactions);
        if self.chain_spec.is_byzantium_active_at_block(block.number()) {
            block.header.receipts_root =
                execution_outcome.ethereum_receipts_root(block.number).unwrap();
            block.header.logs_bloom = execution_outcome.block_logs_bloom(block.number).unwrap();
        }

        execution_outcome
    }

    async fn make_canonical(&self, block_id: &B256, executed_block: ExecutedBlockWithTrieUpdates) {
        let block_number = executed_block.recovered_block.number();
        let block_hash = executed_block.recovered_block.hash();
        let prev_finish_commit_time =
            self.make_canonical_barrier.wait(block_number - 1).await.unwrap();
        let start_time = Instant::now();
        let (tx, rx) = oneshot::channel();
        self.event_tx
            .send(PipeExecLayerEvent::MakeCanonical(MakeCanonicalEvent { executed_block, tx }))
            .unwrap();
        rx.await.unwrap();
        self.storage.update_canonical(block_number, block_hash);
        let elapsed = start_time.elapsed();
        info!(target: "PipeExecService.process",
            block_number=?block_number,
            block_id=?block_id,
            block_hash=?block_hash,
            elapsed=?elapsed,
            "block made canonical"
        );
        let finish_commit_time = Instant::now();
        self.metrics.make_canonical_duration.record(elapsed);
        self.metrics.finish_commit_time_diff.record(finish_commit_time - prev_finish_commit_time);
        self.make_canonical_barrier.notify(block_number, finish_commit_time).unwrap();
    }

    fn init_storage(&self, execution_args: ExecutionArgs) {
        execution_args.block_number_to_block_id.into_iter().for_each(|(block_number, block_id)| {
            self.storage.insert_block_id(block_number, block_id);
        });
    }

    /// Return the filtered valid transactions with sender without changing the relative order of
    /// the transactions.
    fn filter_invalid_txs(
        &self,
        db: &Storage::StateView,
        txs: Vec<TransactionSigned>,
        senders: Vec<Address>,
        base_fee_per_gas: u64,
        gas_limit: u64,
    ) -> (Vec<TransactionSigned>, Vec<Address>, Vec<TxInfo>) {
        let invalid_idxs = filter_invalid_txs(db, &txs, &senders, base_fee_per_gas, gas_limit);
        if invalid_idxs.is_empty() {
            let mut txs_info = Vec::with_capacity(txs.len());
            for (tx, sender) in txs.iter().zip(senders.iter()) {
                txs_info.push(TxInfo {
                    tx_hash: *tx.hash(),
                    sender: *sender,
                    nonce: tx.nonce(),
                    is_discarded: false,
                });
            }
            (txs, senders, txs_info)
        } else {
            let _ = self
                .discard_txs_tx
                .send(invalid_idxs.iter().map(|&idx| txs[idx].hash()).copied().collect::<Vec<_>>());

            let mut filtered_txs = Vec::with_capacity(txs.len() - invalid_idxs.len());
            let mut filtered_senders = Vec::with_capacity(filtered_txs.capacity());
            let mut txs_info = Vec::with_capacity(txs.len());
            for (i, (tx, sender)) in txs.into_iter().zip(senders.into_iter()).enumerate() {
                if invalid_idxs.contains(&i) {
                    txs_info.push(TxInfo {
                        tx_hash: *tx.hash(),
                        sender,
                        nonce: tx.nonce(),
                        is_discarded: true,
                    });
                    continue;
                }

                txs_info.push(TxInfo {
                    tx_hash: *tx.hash(),
                    sender,
                    nonce: tx.nonce(),
                    is_discarded: false,
                });
                filtered_txs.push(tx);
                filtered_senders.push(sender);
            }
            (filtered_txs, filtered_senders, txs_info)
        }
    }
}

/// Return the invalid transaction indexes.
fn filter_invalid_txs<DB: ParallelDatabase>(
    db: DB,
    txs: &[TransactionSigned],
    senders: &[Address],
    base_fee_per_gas: u64,
    gas_limit: u64,
) -> HashSet<usize> {
    let mut gas_limit_exceeded_tx_idx = txs.len();
    let mut tx_gas_limit_sum = 0;
    for (idx, tx) in txs.iter().enumerate() {
        let tx_gas_limit = tx.gas_limit();
        if tx_gas_limit_sum + tx_gas_limit > gas_limit {
            warn!(target: "filter_invalid_txs",
                tx_hash=?txs[idx].hash(),
                sender=?senders[idx],
                block_gas_limit=?gas_limit,
                "gas limit exceeded, truncated to {}",
                idx,
            );
            gas_limit_exceeded_tx_idx = idx;
            break;
        } else {
            tx_gas_limit_sum += tx_gas_limit;
        }
    }

    let mut sender_idx: HashMap<&Address, Vec<usize>> = HashMap::default();
    for (i, sender) in senders[..gas_limit_exceeded_tx_idx].iter().enumerate() {
        sender_idx.entry(sender).or_default().push(i);
    }

    let is_tx_valid = |tx: &TransactionSigned, sender: &Address, account: &mut AccountInfo| {
        if account.nonce != tx.nonce() {
            warn!(target: "filter_invalid_txs",
                tx_hash=?tx.hash(),
                sender=?sender,
                nonce=?tx.nonce(),
                account_nonce=?account.nonce,
                "nonce mismatch"
            );
            return false;
        }
        let gas_spent = U256::from(tx.effective_gas_price(Some(base_fee_per_gas)))
            .saturating_mul(U256::from(tx.gas_limit()))
            .saturating_add(tx.value());
        let total_spent = gas_spent + tx.value();
        if account.balance < total_spent {
            warn!(target: "filter_invalid_txs",
                tx_hash=?tx.hash(),
                sender=?sender,
                balance=?account.balance,
                gas_spent=?gas_spent,
                value=?tx.value(),
                "insufficient balance"
            );
            return false;
        }
        account.balance -= total_spent;
        account.nonce += 1;
        true
    };

    let mut invalid_tx_idxs = sender_idx
        .into_par_iter()
        .flat_map(|(sender, idxs)| {
            if let Some(mut account) = db.basic_ref(*sender).unwrap() {
                idxs.into_iter()
                    .filter(|&idx| !is_tx_valid(&txs[idx], sender, &mut account))
                    .collect()
            } else {
                // Sender does not exist in the state trie, balance is 0
                warn!(target: "filter_invalid_txs",
                    tx_hash=?txs[idxs[0]].hash(),
                    sender=?sender,
                    "insufficient balance"
                );
                idxs
            }
        })
        .collect::<HashSet<_>>();
    invalid_tx_idxs.extend(gas_limit_exceeded_tx_idx..txs.len());
    invalid_tx_idxs
}

/// Called by Coordinator
#[derive(Debug)]
pub struct PipeExecLayerApi<Storage, EthApi> {
    ordered_block_tx: UnboundedSender<ReceivedBlock>,
    execution_result_rx: Mutex<UnboundedReceiver<ExecutionResult>>,
    verified_block_hash_tx: Arc<Channel<B256 /* block id */, Option<B256> /* block hash */>>,
    event_tx: std::sync::mpsc::Sender<PipeExecLayerEvent<EthPrimitives>>,
    storage: Arc<Storage>,
    onchain_config_fetcher: OnchainConfigFetcher<EthApi>,
}

impl<Storage, EthApi> ConfigStorage for PipeExecLayerApi<Storage, EthApi>
where
    Storage: Sync + Send + 'static,
    EthApi: EthCall,
    EthApi::NetworkTypes: RpcTypes<TransactionRequest = TransactionRequest>,
{
    fn fetch_config_bytes(
        &self,
        config_name: OnChainConfig,
        block_number: u64,
    ) -> Option<OnChainConfigResType> {
        Some(self.onchain_config_fetcher.fetch_config_bytes(config_name, block_number))
    }
}

impl<Storage: GravityStorage, EthApi> PipeExecLayerApi<Storage, EthApi> {
    /// Push ordered block to EL for execution.
    /// Returns `None` if the channel has been closed.
    pub fn push_ordered_block(&self, block: OrderedBlock) -> Option<()> {
        self.ordered_block_tx.send(ReceivedBlock::OrderedBlock(block)).ok()
    }

    /// Only used for testing.
    pub fn push_history_block(&self, block: RecoveredBlock<Block>) -> Option<()> {
        self.ordered_block_tx.send(ReceivedBlock::HistoryBlock(block.into())).ok()
    }

    /// Pull executed block hash from EL for verification.
    /// Returns `None` if the channel has been closed.
    pub async fn pull_executed_block_hash(&self) -> Option<ExecutionResult> {
        self.execution_result_rx.lock().await.recv().await
    }

    /// Push verified block hash to EL for commit.
    /// The caller can optionally pass in a verified block hash, which is solely used for the EL
    /// defensive check to ensure the consistency of the block hash before and after verification.
    /// Returns `None` if the channel has been closed.
    pub fn commit_executed_block_hash(
        &self,
        block_id: B256,
        block_hash: Option<B256>,
    ) -> Option<()> {
        self.verified_block_hash_tx.notify(block_id, block_hash)
    }

    /// Wait for the block with the given block number to be persisted in the storage.
    /// Returns `None` if the channel has been closed.
    pub async fn wait_for_block_persistence(&self, block_number: u64) -> Option<()> {
        let (tx, rx) = oneshot::channel();
        self.event_tx
            .send(PipeExecLayerEvent::WaitForPersistence(WaitForPersistenceEvent {
                block_number,
                tx,
            }))
            .ok()?;
        rx.await.ok()
    }

    /// Get the block id by block number.
    pub fn get_block_id(&self, block_number: u64) -> Option<B256> {
        self.storage.get_block_id(block_number)
    }
}

impl<Storage, EthApi> Drop for PipeExecLayerApi<Storage, EthApi> {
    fn drop(&mut self) {
        self.verified_block_hash_tx.close();
    }
}

/// Create a new `PipeExecLayerApi` instance and launch a `PipeExecService`.
pub fn new_pipe_exec_layer_api<Storage, EthApi>(
    chain_spec: Arc<ChainSpec>,
    storage: Storage,
    latest_block_header: Header,
    latest_block_hash: B256,
    execution_args_rx: oneshot::Receiver<ExecutionArgs>,
    eth_api: EthApi,
) -> PipeExecLayerApi<Storage, EthApi>
where
    Storage: GravityStorage,
    EthApi: EthCall,
    EthApi::NetworkTypes: RpcTypes<TransactionRequest = TransactionRequest>,
{
    let (ordered_block_tx, ordered_block_rx) = tokio::sync::mpsc::unbounded_channel();
    let (execution_result_tx, execution_result_rx) = tokio::sync::mpsc::unbounded_channel();
    let verified_block_hash_ch = Arc::new(Channel::new());
    let (event_tx, event_rx) = std::sync::mpsc::channel();
    let (discard_txs_tx, discard_txs_rx) = tokio::sync::mpsc::unbounded_channel();

    let storage = Arc::new(storage);
    let onchain_config_fetcher = OnchainConfigFetcher::new(eth_api);

    let latest_block_number = latest_block_header.number;
    let epoch = onchain_config_fetcher.fetch_epoch(latest_block_number);
    info!(target: "PipeExecService.new_pipe_exec_layer_api",
        latest_block_number=?latest_block_number,
        latest_block_hash=?latest_block_hash,
        epoch=?epoch,
        "new pipe exec layer api"
    );

    let start_time = Instant::now();
    let service = PipeExecService {
        core: Arc::new(Core {
            execution_result_tx,
            verified_block_hash_rx: verified_block_hash_ch.clone(),
            storage: storage.clone(),
            evm_config: EthEvmConfig::new(chain_spec.clone()),
            chain_spec,
            event_tx: event_tx.clone(),
            execute_block_barrier: Channel::new_with_states([(
                latest_block_number,
                ExecuteBlockContext {
                    parent_header: latest_block_header,
                    prev_start_execute_time: start_time,
                    epoch,
                },
            )]),
            merklize_barrier: Channel::new_with_states([(latest_block_number, ())]),
            seal_barrier: Channel::new_with_states([(latest_block_number, latest_block_hash)]),
            make_canonical_barrier: Channel::new_with_states([(latest_block_number, start_time)]),
            discard_txs_tx,
            cache: PERSIST_BLOCK_CACHE.clone(),
            metrics: PipeExecLayerMetrics::default(),
        }),
        ordered_block_rx,
        execution_args_rx,
    };
    tokio::spawn(service.run());

    PIPE_EXEC_LAYER_EVENT_BUS.get_or_init(|| {
        Box::new(PipeExecLayerEventBus {
            event_rx: std::sync::Mutex::new(Some(event_rx)),
            discard_txs: tokio::sync::Mutex::new(Some(discard_txs_rx)),
        })
    });

    PipeExecLayerApi {
        ordered_block_tx,
        execution_result_rx: Mutex::new(execution_result_rx),
        verified_block_hash_tx: verified_block_hash_ch,
        event_tx,
        storage,
        onchain_config_fetcher,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use alloy_consensus::TxLegacy;
    use alloy_primitives::{Address, Signature, U256};
    use reth_ethereum_primitives::{Transaction, TransactionSigned};
    use reth_revm::state::{AccountInfo, Bytecode};
    use revm::{
        primitives::{StorageKey, StorageValue},
        DatabaseRef,
    };
    use std::collections::HashMap;

    // Mock database for testing
    #[derive(Debug, Default)]
    struct MockDatabase {
        accounts: HashMap<Address, AccountInfo>,
    }

    impl MockDatabase {
        fn new() -> Self {
            Self::default()
        }

        fn insert_account(&mut self, address: Address, account: AccountInfo) {
            self.accounts.insert(address, account);
        }
    }

    impl DatabaseRef for MockDatabase {
        type Error = std::convert::Infallible;

        fn basic_ref(&self, address: Address) -> Result<Option<AccountInfo>, Self::Error> {
            Ok(self.accounts.get(&address).cloned())
        }

        fn code_by_hash_ref(&self, _code_hash: B256) -> Result<Bytecode, Self::Error> {
            unreachable!()
        }

        fn storage_ref(
            &self,
            _address: Address,
            _index: StorageKey,
        ) -> Result<StorageValue, Self::Error> {
            unreachable!()
        }

        fn block_hash_ref(&self, _number: u64) -> Result<B256, Self::Error> {
            unreachable!()
        }
    }

    fn create_test_transaction(nonce: u64, gas_limit: u64, gas_price: u128) -> TransactionSigned {
        TransactionSigned::new_unhashed(
            Transaction::Legacy(TxLegacy { nonce, gas_price, gas_limit, ..Default::default() }),
            Signature::test_signature(),
        )
    }

    #[test]
    fn test_filter_invalid_txs_empty_input() {
        let db = MockDatabase::new();
        let txs = vec![];
        let senders = vec![];
        let base_fee_per_gas = 20_000_000_000u64; // 20 gwei
        let gas_limit = 30_000_000u64; // 30M gas

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert!(invalid_idxs.is_empty());
    }

    #[test]
    fn test_filter_invalid_txs_account_not_exists() {
        let db = MockDatabase::new();
        let sender = Address::random();

        // create a transaction, but the account does not exist
        let tx = create_test_transaction(0, 21_000, 25_000_000_000);
        let txs = vec![tx];
        let senders = vec![sender];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64;

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert_eq!(invalid_idxs.len(), 1);
        assert!(invalid_idxs.contains(&0));
    }

    #[test]
    fn test_filter_invalid_txs_nonce_mismatch() {
        let mut db = MockDatabase::new();
        let sender = Address::random();

        // the account exists, but the nonce does not match
        let account = AccountInfo {
            balance: U256::from(1_000_000_000_000_000_000u64), // 1 ETH
            nonce: 5,                                          // 账户 nonce 是 5
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender, account);

        // the transaction nonce is 0, but the account nonce is 5
        let tx = create_test_transaction(0, 21_000, 25_000_000_000);
        let txs = vec![tx];
        let senders = vec![sender];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64;

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert_eq!(invalid_idxs.len(), 1);
        assert!(invalid_idxs.contains(&0));
    }

    #[test]
    fn test_filter_invalid_txs_insufficient_balance() {
        let mut db = MockDatabase::new();
        let sender = Address::random();

        // the account has insufficient balance
        let account = AccountInfo {
            balance: U256::from(1_000_000_000u64), // 1 Gwei
            nonce: 0,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender, account);

        // fee = gas_price * gas_limit + value = 25_000_000_000 * 21_000 + 0 =
        // 525_000_000_000_000
        let tx = create_test_transaction(0, 21_000, 25_000_000_000);
        let txs = vec![tx];
        let senders = vec![sender];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64;

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert_eq!(invalid_idxs.len(), 1);
        assert!(invalid_idxs.contains(&0));
    }

    #[test]
    fn test_filter_invalid_txs_gas_limit_exceeded() {
        let mut db = MockDatabase::new();
        let sender = Address::random();

        // the account has enough balance
        let account = AccountInfo {
            balance: U256::from(1_000_000_000_000_000_000u64), // 1 ETH
            nonce: 0,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender, account);

        // create multiple transactions, the cumulative gas limit exceeds the block limit
        let tx1 = create_test_transaction(0, 20_000_000, 25_000_000_000); // 20M gas
        let tx2 = create_test_transaction(1, 20_000_000, 25_000_000_000); // 20M gas
        let txs = vec![tx1, tx2];
        let senders = vec![sender, sender];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64; // 30M gas limit

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert_eq!(invalid_idxs.len(), 1);
        assert!(invalid_idxs.contains(&1));
    }

    #[test]
    fn test_filter_invalid_txs_valid_transactions() {
        let mut db = MockDatabase::new();
        let sender = Address::random();

        // 账户有足够余额
        let account = AccountInfo {
            balance: U256::from(1_000_000_000_000_000_000u64), // 1 ETH
            nonce: 0,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender, account);

        // create valid transactions
        let tx1 = create_test_transaction(0, 21_000, 25_000_000_000);
        let tx2 = create_test_transaction(1, 21_000, 25_000_000_000);
        let txs = vec![tx1, tx2];
        let senders = vec![sender, sender];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64;

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert!(invalid_idxs.is_empty());
    }

    #[test]
    fn test_filter_invalid_txs_mixed_scenarios() {
        let mut db = MockDatabase::new();
        let sender1 = Address::random();
        let sender2 = Address::random();
        let sender3 = Address::random();

        let account1 = AccountInfo {
            balance: U256::from(1_000_000_000u64), // 1 Gwei
            nonce: 0,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender1, account1);

        let account2 = AccountInfo {
            balance: U256::from(1_000_000_000u64), // 1 Gwei
            nonce: 5,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender2, account2);

        let account3 = AccountInfo {
            balance: U256::from(1_000_000_000u64), // 1 Gwei
            nonce: 0,
            code_hash: B256::default(),
            code: None,
        };
        db.insert_account(sender3, account3);

        // create mixed scenarios transactions
        let tx1 = create_test_transaction(0, 21_000, 25); // sender1: valid
        let tx2 = create_test_transaction(0, 21_000, 25); // sender1: nonce does not match
        let tx3 = create_test_transaction(1, 21_000, 25_000_000); // sender1: insufficient balance
        let tx4 = create_test_transaction(5, 21_000, 25); // sender2: valid
        let tx5 = create_test_transaction(2, 21_000, 25); // sender1: nonce does not match
        let tx6 = create_test_transaction(6, 30_000_000, 25); // sender2: gas limit exceeds
        let tx7 = create_test_transaction(0, 21000, 25); // sender3: truncated
        let txs = vec![tx1, tx2, tx3, tx4, tx5, tx6, tx7];
        let senders = vec![sender1, sender1, sender1, sender2, sender2, sender2, sender3];
        let base_fee_per_gas = 20_000_000_000u64;
        let gas_limit = 30_000_000u64;

        let invalid_idxs = filter_invalid_txs(&db, &txs, &senders, base_fee_per_gas, gas_limit);
        assert_eq!(invalid_idxs.len(), 5, "invalid_idxs: {invalid_idxs:?}");
        assert!(invalid_idxs.contains(&1));
        assert!(invalid_idxs.contains(&2));
        assert!(invalid_idxs.contains(&4));
        assert!(invalid_idxs.contains(&5));
        assert!(invalid_idxs.contains(&6));
    }
}
